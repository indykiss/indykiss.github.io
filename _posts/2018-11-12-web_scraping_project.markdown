---
layout: post
title:      "Web scraping project"
date:       2018-11-12 17:03:34 +0000
permalink:  web_scraping_project
---


I've recently started my web scraping project after hopping through the Ruby curriculm with a semi-irregular schedule. I had a work trip to London then a conference to San Antonio that derailed me, then started fostering a dog (golden doodle named Bojangles!) and now just getting back on track with my programming schedule. 

One of my responsibilities at work is to create a weekly newsletter (called *In the Know*) on several key business topics. These topics tend to fall under a certain search parameter, ex: word count over 200 and mentions a variation of customer experience at least four times. I also tend to grab articles from the same ~15 reputable websites for each topic every week. 

Originally, I created a schema for a web scraper that could scrape these ~60 total sites and return recent, pertinent articles that I could then visually audit and add into the newsletter. It seems to be a worthwhile goal to automate my job whenever possible ;) 

After realizing that this would take several weeks, I've decided to scrape a website selling books instead as practice (I'm basically a corporate librarian), so this still fits my interests. 

*In The Know* scraping idea for another time!
